{"cells":[{"cell_type":"markdown","metadata":{"id":"IagZMs0_qjdL"},"source":["# 1. Introduction\n","\n","Welcome to your third assignment. In this assignment, you will build a deep neural network step by step. In this notebook, you will implement all the functions required to build a neural network.\n","\n","After finishing this assignment, you will have a deeper understanding of the process of training a deep neural network, which only consists of three steps: forward propagation, backward propagation and update."]},{"cell_type":"markdown","metadata":{"id":"yGFR00CQvoaH"},"source":["# 2. Important notice\n","\n","## 2.1 Packages\n","All the packages that you need to finish this assignment are listed below.\n","*   numpy : the fundamental package for scientific computing with Python.\n","*   matplotlib : a comprehensive library for creating static, animated, and interactive visualizations in Python.\n","*   math : Python has a built-in module that you can use for mathematical tasks.\n","*   sklearn.metrics: we use this to compute the f1 score\n","*   from google.colab import drive: used to access data in your google drive\n","\n","⚠️ **WARNING** ⚠️:\n","*   Please do not import any other packages.\n","*   np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please don't change the seed.\n","\n","## 2.2 Todo\n","```\n","### START CODE HERE ### (≈ n lines of code)\n","...\n","### END CODE HERE ###\n","```\n","❗ **Important** ❗: Please do not change the code outside this code bracket in the first part.\n","\n","### Common Notation\n","* $C$: number of classes\n","* $n$: number of samples\n","* $f^{[l]}$: the dimension of outputs in layer $l$, but $f^{[0]}$ is the input dimension\n","* $Z^{[l]} = A^{[l-1]}W^{[l]} + b^{[l]}$\n","    * $Z^{[l]}$: the output of layer $l$ in the shape $(n, f^{[l]})$\n","    * $A^{[l]}$: the activation of $Z^{[l]}$ in the shape $(n, f^{[l]})$, but $A^{[0]}$ is input $X$\n","    * $W^{[l]}$: the weight in layer $l$ in the shape $(f^{[l-1]}, f^{[l]})$\n","    * $b^{[l]}$: the bias in layer $l$ in the shape $(1, f^{[l]})$\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fmTH9UkeqdYf"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from sklearn.metrics import f1_score\n","\n","outputs = {}"]},{"cell_type":"markdown","metadata":{"id":"w35ZkTwMc00G"},"source":["# 3. Neural network\n","In this section, you will need to implement a deep neural network from scratch all by yourself. If you are familiar with deep learning library, such as Tensorflow or PyTorch, it may seems easy for you. But if you don't, don't worry because we will guide you step by step. All you need to do is to follow the instructions and understand how each part works.\n","\n","As mentioned before, the process of training a deep neural network is composed of three steps: forward propagation, backward propagation, and update, so all the to-do in this section will be related to these three steps."]},{"cell_type":"markdown","metadata":{"id":"P_krGKUNg_Ix"},"source":["## 3.1 Implement a linear layer (10%)\n","First, we will start by implementing one of the most commonly used layers in the deep neural network, called the dense layer. The dense layer is a linear layer applying a linear transformation to the incoming data:\n","$Z = AW + b$, where $W$ and $b$ are the weight and bias.\n","\n","**Note**: Dense layers, also known as Fully-connected layers, connect every input neuron to every output neuron and are commonly used in neural networks.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"x0KHo8w9yqbY"},"outputs":[],"source":["class Dense():\n","    def __init__(self, n_x, n_y, seed=1):\n","        self.n_x = n_x\n","        self.n_y = n_y\n","        self.seed = seed\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Argument:\n","        self.n_x -- size of the input layer\n","        self.n_y -- size of the output layer\n","        self.parameters -- python dictionary containing your parameters:\n","                           W -- weight matrix of shape (n_x, n_y)\n","                           b -- bias vector of shape (1, n_y)\n","        \"\"\"\n","        sd = np.sqrt(6.0 / (self.n_x + self.n_y))\n","        np.random.seed(self.seed)\n","        W = np.random.uniform(-sd, sd, (self.n_y, self.n_x)).T      # the transpose here is just for the code to be compatible with the old codes\n","        b = np.zeros((1, self.n_y))\n","\n","        assert(W.shape == (self.n_x, self.n_y))\n","        assert(b.shape == (1, self.n_y))\n","\n","        self.parameters = {\"W\": W, \"b\": b}\n","\n","    def forward(self, A):\n","        \"\"\"\n","        Implement the linear part of a layer's forward propagation.\n","\n","        Arguments:\n","        A -- activations from previous layer (or input data) with the shape (n, f^[l-1])\n","        self.cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n","\n","        Returns:\n","        Z -- the input of the activation function, also called pre-activation parameter with the shape (n, f^[l])\n","        \"\"\"\n","\n","        # GRADED FUNCTION: linear_forward\n","        ### START CODE HERE ### (≈ 2 line of code)\n","        Z = np.matmul(A, self.parameters['W']) + self.parameters['b']\n","        self.cache = (A, self.parameters['W'], self.parameters['b'])\n","        ### END CODE HERE ###\n","\n","        assert(Z.shape == (A.shape[0], self.parameters[\"W\"].shape[1]))\n","\n","        return Z\n","\n","    def backward(self, dZ):\n","        \"\"\"\n","        Implement the linear portion of backward propagation for a single layer (layer l)\n","\n","        Arguments:\n","        dZ -- Gradient of the loss with respect to the linear output (of current layer l), same shape as Z\n","        self.cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n","        self.dW -- Gradient of the loss with respect to W (current layer l), same shape as W\n","        self.db -- Gradient of the loss with respect to b (current layer l), same shape as b\n","\n","        Returns:\n","        dA_prev -- Gradient of the loss with respect to the activation (of the previous layer l-1), same shape as A_prev\n","\n","        \"\"\"\n","        A_prev, W, b = self.cache\n","        m = A_prev.shape[0]\n","\n","        # GRADED FUNCTION: linear_backward\n","        ### START CODE HERE ### (≈ 3 lines of code)\n","        self.dW = 1/m * np.matmul(A_prev.T, dZ) \n","        self.db = np.array([1/m * np.sum(dZ, axis=0)])\n","        dA_prev = np.matmul(dZ, W.T)\n","        ### END CODE HERE ###\n","\n","        assert (dA_prev.shape == A_prev.shape)\n","        assert (self.dW.shape == self.parameters[\"W\"].shape)\n","        assert (self.db.shape == self.parameters[\"b\"].shape)\n","\n","        return dA_prev\n","\n","    def update(self, learning_rate):\n","        \"\"\"\n","        Update parameters using gradient descent\n","\n","        Arguments:\n","        learning rate -- step size\n","        \"\"\"\n","\n","        # GRADED FUNCTION: linear_update_parameters\n","        ### START CODE HERE ### (≈ 2 lines of code)\n","        self.parameters[\"W\"] = self.parameters[\"W\"] - (learning_rate * self.dW)\n","        self.parameters[\"b\"] = self.parameters[\"b\"] - (learning_rate * self.db)\n","        ### END CODE HERE ###"]},{"cell_type":"markdown","metadata":{"id":"syt1bV3bdI_f"},"source":["## 3.2. Activation function layer (25%)\n","\n","In this section, you will need to implement activation function layers. There are many activation functions, such as sigmoid function, softmax function, ReLU function and etc.\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Nnuv8MmebMgg"},"outputs":[],"source":["class Activation():\n","    def __init__(self, activation_function, loss_function, alpha=None, gamma=None):\n","        self.activation_function = activation_function\n","        self.loss_function = loss_function\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, Z):\n","        if self.activation_function == \"sigmoid\":\n","            \"\"\"\n","            Implements the sigmoid activation in numpy\n","\n","            Arguments:\n","            Z -- numpy array of any shape\n","            self.cache -- stores Z as well, useful during backpropagation\n","\n","            Returns:\n","            A -- output of sigmoid(z), same shape as Z\n","            \"\"\"\n","\n","            # GRADED FUNCTION: sigmoid_forward\n","            ### START CODE HERE ### (≈ 8 lines of code)\n","            A = np.zeros(Z.shape)\n","            for i in range(Z.shape[0]):\n","                for j in range(Z.shape[1]):\n","                    if Z[i][j] >= 0:\n","                        A[i][j] = 1 / (1 + np.exp(-Z[i][j])) \n","                    else:\n","                        A[i][j] = np.exp(Z[i][j]) / (1 + np.exp(Z[i][j]))\n","            self.cache = Z\n","            ### END CODE HERE ###\n","\n","            return A\n","        elif self.activation_function == \"relu\":\n","            \"\"\"\n","            Implement the RELU function in numpy\n","            Arguments:\n","            Z -- numpy array of any shape\n","            self.cache -- stores Z as well, useful during backpropagation\n","            Returns:\n","            A -- output of relu(z), same shape as Z\n","\n","            \"\"\"\n","\n","            # GRADED FUNCTION: relu_forward\n","            ### START CODE HERE ### (≈ 2 lines of code)\n","            A = np.maximum(Z, 0)\n","            self.cache = Z\n","            ### END CODE HERE ###\n","\n","            assert(A.shape == Z.shape)\n","\n","            return A\n","        elif self.activation_function == \"softmax\":\n","            \"\"\"\n","            Implements the softmax activation in numpy\n","\n","            Arguments:\n","            Z -- np.array with shape (n, C)\n","            self.cache -- stores Z as well, useful during backpropagation\n","\n","            Returns:\n","            A -- output of softmax(z), same shape as Z\n","            \"\"\"\n","\n","            # GRADED FUNCTION: softmax_forward\n","            ### START CODE HERE ### (≈ 3 lines of code)\n","            b = np.max(Z, axis=1, keepdims=True)\n","            A = (np.exp(Z - b)) / np.sum(np.exp(Z - b), axis=1, keepdims=True)\n","            self.cache = Z\n","            ### END CODE HERE ###\n","\n","            return A\n","        else:\n","            assert 0, f\"you're using undefined activation function {self.activation_function}\"\n","\n","\n","    def backward(self, dA=None, Y=None):\n","        if self.activation_function == \"sigmoid\":\n","            \"\"\"\n","            Implement the backward propagation for a single SIGMOID unit.\n","            Arguments:\n","            dA -- post-activation gradient, of any shape\n","            self.cache -- 'Z' where we store for computing backward propagation efficiently\n","            Returns:\n","            dZ -- Gradient of the loss with respect to Z\n","            \"\"\"\n","\n","            # GRADED FUNCTION: sigmoid_backward\n","            ### START CODE HERE ### (≈ 9 lines of code)\n","            Z = self.cache\n","            dZ = np.zeros(Z.shape)\n","            for i in range(Z.shape[0]):\n","                for j in range(Z.shape[1]):\n","                    if Z[i][j] >= 0:\n","                        sig = 1 / (1 + np.exp(-Z[i][j])) \n","                        dZ[i][j] = sig * (1 - sig) * dA[i][j]\n","                    else:\n","                        sig = np.exp(Z[i][j]) / (1 + np.exp(Z[i][j]))\n","                        dZ[i][j] = sig * (1 - sig) * dA[i][j]\n","            ### END CODE HERE ###\n","\n","            assert (dZ.shape == Z.shape)\n","\n","            return dZ\n","\n","        elif self.activation_function == \"relu\":\n","            \"\"\"\n","            Implement the backward propagation for a single RELU unit.\n","            Arguments:\n","            dA -- post-activation gradient, of any shape\n","            self.cache -- 'Z' where we store for computing backward propagation efficiently\n","            Returns:\n","            dZ -- Gradient of the loss with respect to Z\n","            \"\"\"\n","\n","            # GRADED FUNCTION: relu_backward\n","            ### START CODE HERE ### (≈ 3 lines of code)\n","            Z = self.cache\n","            dg = np.where(Z > 0, 1, 0)\n","            dZ = dA * dg\n","            ### END CODE HERE ###\n","\n","            assert (dZ.shape == Z.shape)\n","\n","            return dZ\n","\n","        elif self.activation_function == \"softmax\" and self.loss_function == 'cross_entropy':\n","            \"\"\"\n","            Implement the backward propagation for a [SOFTMAX->CCE LOSS] unit.\n","            Arguments:\n","            Y -- true \"label\" vector (one hot vector, for example: [1,0,0] represents rock, [0,1,0] represents paper, [0,0,1] represents scissors\n","                                      in a Rock-Paper-Scissors, shape: (n, C)\n","            self.cache -- 'Z' where we store for computing backward propagation efficiently\n","            Returns:\n","            dZ -- Gradient of the cost with respect to Z\n","            \"\"\"\n","\n","            # GRADED FUNCTION: softmax_CCE_backward\n","            ### START CODE HERE ### (≈ 3 lines of code)\n","            Z = self.cache\n","            s = (np.exp(Z)) / np.sum(np.exp(Z), axis=1, keepdims=True)\n","            dZ = s - Y\n","            ### END CODE HERE ###\n","\n","            assert (dZ.shape == self.cache.shape)\n","\n","            return dZ\n","        elif self.activation_function == \"softmax\" and self.loss_function == 'focal_loss':\n","            \"\"\"\n","            Implement the backward propagation for a [SOFTMAX->FOCAL LOSS] unit.\n","            Arguments:\n","            Y -- true \"label\" vector (one hot vector, for example: [1,0,0] represents rock, [0,1,0] represents paper, [0,0,1] represents scissors\n","                                      in a Rock-Paper-Scissors, shape: (n, C)\n","            self.cache -- 'Z' where we store for computing backward propagation efficiently\n","            Returns:\n","            dZ -- Gradient of the cost with respect to Z\n","            alpha -- weighting factors correspond to each class, shape: (C,)\n","            gamma -- modulating factor, a float\n","            \"\"\"\n","\n","            # GRADED FUNCTION: softmax_focalLoss_backward\n","            ## START CODE HERE ### (≈ 10 lines of code)\n","            Z = self.cache\n","            p = (np.exp(Z)) / np.sum(np.exp(Z), axis=1, keepdims=True)\n","            p_it = np.sum(p * Y, axis=1)\n","            dZ = np.zeros(Z.shape)\n","            alpha_t = np.sum(self.alpha * Y, axis=1, keepdims=True)\n","            for i in range(Z.shape[0]):\n","                for j in range(Z.shape[1]):\n","                    if Y[i][j] == 1:\n","                        dZ[i][j] = alpha_t[i] * ((self.gamma * np.power(1 - p_it[i], self.gamma - 1) * np.log(p_it[i] + 1e-5) * (p[i][j] - np.power(p[i][j], 2))) \n","                                    - (np.power(1 - p_it[i], self.gamma) * (1 - p_it[i])))\n","                    else:\n","                        dZ[i][j] = alpha_t[i] * ((self.gamma * np.power(1 - p_it[i], self.gamma - 1) * np.log(p_it[i] + 1e-5) * (-p[i][j] * (p_it[i]))) \n","                                    - (np.power(1 - p_it[i], self.gamma) * (-p[i][j])))\n","            ## END CODE HERE ###\n","\n","            assert (dZ.shape == self.cache.shape)\n","\n","            return dZ"]},{"cell_type":"markdown","metadata":{"id":"RYqpQu6Eye7h"},"source":["## 3.3. Model (10%)\n","Alright, now you have all the tools that are needed to build a model. Let's get started! 😀\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0JGMzfIDCSVz"},"outputs":[],"source":["class Model():\n","    def __init__(self, units, activation_functions, loss_function, alpha=None, gamma=None):\n","        self.units = units\n","        self.activation_functions = activation_functions\n","        self.loss_function = loss_function\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.initialize_parameters()\n","\n","    def initialize_parameters(self):\n","        \"\"\"\n","        Arguments:\n","        self.units -- number of nodes/units for each layer, starting from the input dimension and ending with the output dimension (i.e., [4, 4, 1])\n","        self.activation_functions -- activation functions used in each layer (i.e, [\"relu\", \"sigmoid\"])\n","        self.loss_function -- [\"cross_entropy\", \"focal_loss\"]\n","        self.alpha -- weighting factors used by focal loss correspond to each class, shape: (C,)\n","        self.gamma -- a float, used by focal loss\n","        \"\"\"\n","        self.linear = []        # a list to store the dense layers when initializing the model\n","        self.activation = []    # a list to store the activation function layers when initializing the model\n","\n","        for i in range(len(self.units)-1):\n","            dense = Dense(self.units[i], self.units[i+1], i)\n","            self.linear.append(dense)\n","\n","        for i in range(len(self.activation_functions)):\n","            self.activation.append(Activation(self.activation_functions[i], self.loss_function, self.alpha, self.gamma))\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Arguments:\n","        X -- input data: shape (n, f)\n","\n","        Returns:\n","        A -- output of L-layer neural network, probability vector corresponding to your label predictions, shape (n, C)\n","        \"\"\"\n","        A = X\n","\n","        # GRADED FUNCTION: model_forward\n","        ### START CODE HERE ### (≈ 4 lines of code)\n","        for i in range(len(self.units) - 1):\n","            Z = self.linear[i].forward(A)\n","            A = self.activation[i].forward(Z)\n","        ### END CODE HERE ###\n","\n","        return A\n","\n","    def backward(self, AL=None, Y=None):\n","        \"\"\"\n","        Arguments:\n","        For multi-class classification,\n","        AL -- output of L-layer neural network, probability vector corresponding to your label predictions, shape (n, C)\n","        Y -- true \"label\" vector (one hot vector, for example: [1,0,0] represents rock, [0,1,0] represents paper, [0,0,1] represents scissors\n","                                      in a Rock-Paper-Scissors, shape: (n, C)\n","\n","        Returns:\n","        dA_prev -- post-activation gradient\n","        \"\"\"\n","\n","        L = len(self.linear)\n","        C = Y.shape[1]\n","\n","        # assertions\n","        warning = 'Warning: only the following 4 combinations are allowed! \\n \\\n","                    1. binary classification: sigmoid + cross_entropy) \\n \\\n","                    2. binary classification: softmax + focal_loss) \\n \\\n","                    3. multi-class classification: softmax + cross_entropy) \\n \\\n","                    4. multi-class classification: softmax + focal_loss)'\n","        assert self.loss_function in [\"cross_entropy\", \"focal_loss\"], \"you're using undefined loss function!\"\n","        if Y.shape[1] <= 2:                                 # in binary classification\n","            if self.loss_function == \"cross_entropy\":\n","                assert self.activation_functions[-1] == 'sigmoid', warning\n","                assert self.units[-1] == 1, \"you should set last dim to 1 when using sigmoid + cross_entropy in binary classification!\"\n","            elif self.loss_function  == \"focal_loss\":\n","                assert self.activation_functions[-1] == 'softmax', warning\n","                assert self.units[-1] == 2, \"you should set last dim to 2 when using softmax + focal_loss in binary classification!\"\n","        else:                                               # in multi-class classification\n","            assert self.activation_functions[-1] == 'softmax', warning\n","            assert self.units[-1] == Y.shape[1], f\"you should set last dim to {Y.shape[1]}(the number of classes) in multi-class classification!\"\n","\n","        # GRADED FUNCTION: model_backward\n","        ### START CODE HERE ### (≈ 20 lines of code)\n","\n","        if self.activation_functions[-1] == \"sigmoid\":\n","            if self.loss_function == 'cross_entropy':\n","                # Initializing the backpropagation\n","                dAL = -(np.divide(Y, AL + 1e-5) - np.divide(1 - Y, 1 - AL + 1e-5))\n","\n","                # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL\". Outputs: \"dA_prev\"\n","                dZ = self.activation[-1].backward(dA=dAL, Y=Y)\n","                dA_prev = self.linear[-1].backward(dZ)\n","        elif self.activation_functions[-1] == \"softmax\":\n","            # Initializing the backpropagation\n","            dZ = self.activation[-1].backward(Y=Y)\n","\n","            # Lth layer (LINEAR) gradients. Inputs: \"dZ\". Outputs: \"dA_prev\"\n","            dA_prev = self.linear[-1].backward(dZ)\n","\n","        # Loop from l=L-2 to l=0\n","        # lth layer: (RELU -> LINEAR) gradients.\n","        # Inputs: \"dA_prev\". Outputs: \"dA_prev\"\n","        for i in range(L-2, -1, -1):\n","            dZ = self.activation[i].backward(dA=dA_prev, Y=Y)\n","            dA_prev = self.linear[i].backward(dZ)\n","        ### END CODE HERE ###\n","\n","        return dA_prev\n","\n","    def update(self, learning_rate):\n","        \"\"\"\n","        Arguments:\n","        learning_rate -- step size\n","        \"\"\"\n","\n","        L = len(self.linear)\n","\n","        # GRADED FUNCTION: model_update_parameters\n","        ### START CODE HERE ### (≈ 2 lines of code)\n","        for i in range(L):\n","            self.linear[i].parameters[\"W\"] = self.linear[i].parameters[\"W\"] - (learning_rate * self.linear[i].dW)\n","            self.linear[i].parameters[\"b\"] = self.linear[i].parameters[\"b\"] - (learning_rate * self.linear[i].db)\n","        ### END CODE HERE ###"]},{"cell_type":"markdown","metadata":{"id":"SmSBVaQOSRrk"},"source":["# 4. Loss function (15%)\n","In this section, you will implement the loss function. We use binary cross-entropy loss for binary classification and categorical cross-entropy loss for multi-class classification. You need to compute the loss, because you want to check if your model is actually learning. Cross-entropy loss is minimized, where smaller values represent a better model than larger values. A model that predicts perfect probabilities has a cross entropy or log loss of 0.0.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ScdQdj85uC0P"},"source":["## 4.1. Binary cross-entropy loss (5%)\n","**Exercise**: Compute the binary cross-entropy loss $L$, using the following formula:  $$-\\frac{1}{n} \\sum\\limits_{i = 1}^{n} (y^{(i)}\\log\\left(a^{[L] (i)}+ϵ\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}+ϵ\\right)), where\\ ϵ=1e-5$$"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MjBT0eYQaY81"},"outputs":[],"source":["# GRADED FUNCTION: compute_BCE_loss\n","\n","def compute_BCE_loss(AL, Y):\n","    \"\"\"\n","    Implement the binary cross-entropy loss function using the above formula.\n","\n","    Arguments:\n","    AL -- probability vector corresponding to your label predictions, shape (n, 1)\n","    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (n, 1)\n","\n","    Returns:\n","    loss -- binary cross-entropy loss\n","    \"\"\"\n","\n","    n = Y.shape[0]\n","\n","    # Compute loss from aL and y.\n","    ### START CODE HERE ### (≈ 1 line of code)\n","    loss = -1/n * np.sum(Y * np.log(AL + 1e-5) + (1 - Y) * np.log(1 - AL + 1e-5))\n","    ### END CODE HERE ###\n","\n","    loss = np.squeeze(loss)      # To make sure your loss's shape is what we expect (e.g. this turns [[17]] into 17).\n","    assert(loss.shape == ())\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"aealRyKbcQzG"},"source":["## 4.2. Categorical cross-entropy loss (CCE) (5%)\n","**Exercise**:\n","Compute the categorical cross-entropy loss $L$, using the following formula: $$-\\frac{1}{n} \\sum\\limits_{i = 1}^{n} (y^{(i)}\\log\\left(a^{[L] (i)}+ϵ\\right)),\\ ϵ = 1e-5$$\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Owx-kTdcfxV5"},"outputs":[],"source":["# GRADED FUNCTION: compute_CCE_loss\n","\n","def compute_CCE_loss(AL, Y):\n","    \"\"\"\n","    Implement the categorical cross-entropy loss function using the above formula.\n","\n","    Arguments:\n","    AL -- probability vector corresponding to your label predictions, shape (n, C)\n","    Y -- true \"label\" vector (one hot vector, for example: [1,0,0] represents rock, [0,1,0] represents paper, [0,0,1] represents scissors\n","                                      in a Rock-Paper-Scissors, shape: (n, C)\n","\n","    Returns:\n","    loss -- categorical cross-entropy loss\n","    \"\"\"\n","\n","    n = Y.shape[0]\n","\n","    # Compute loss from aL and y.\n","    ### START CODE HERE ### (≈ 1 line of code)\n","    loss = -1/n * np.sum(Y * np.log(AL + 1e-5))\n","    ### END CODE HERE ###\n","\n","    loss = np.squeeze(loss)      # To make sure your loss's shape is what we expect (e.g. this turns [[17]] into 17).\n","    assert(loss.shape == ())\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"8wJ5Ial2tzsl"},"source":["## 4.3. Focal loss (5%)\n","**Exercise**:\n","If we think of the CCE loss elementwisely, the above equation can be re-written in the form below:\n","$$-\\frac{1}{n} \\sum\\limits_{i = 1}^{n} ( \\sum\\limits_{j = 1}^{c} (y_{ij}\\log\\left(a^{[L]}_{ij}+ϵ\\right))), \\ ϵ = 1e-5$$\n","\n","To handle the imbalance dataset, we can use the focal loss, which adds the weighting factor $\\alpha$ and the modulating term $(1-a^{[L]}_{ij})^\\gamma$. To compute the focal loss, you can use the following equation:\n","$$-\\frac{1}{n} \\sum\\limits_{i = 1}^{n} (\\sum\\limits_{j = 1}^{c} (\\alpha_{j} (1-a^{[L]}_{ij})^\\gamma * y_{ij}\\log\\left(a^{[L]}_{ij}+ϵ\\right))),$$\n","where\n","* $\\ ϵ = 1e-5$\n","* $\\alpha$ is the weighting factors in the shape $(c,)$, where ${\\alpha}_i$ corresponds to the class $i$\n","* $\\gamma$ is a modulating factor\n","* $n$ is the number of examples\n","* $c$ is the number of classes\n","\n","Since $y_i$ would be a one-hot vector, we can further simplify the equation to\n","$$\n","\\text{Focal Loss} =\n","-\\frac{1}{n} \\sum_{i=1}^{n} \\alpha_t (1 - p_{it})^\\gamma \\log(p_{it}+ϵ)\n","$$\n","where\n","* $p$: $a^{[L]}$\n","* $p_{ij}$: for the $i$th example, the predicted probability for the $j$th class\n","* $p_{it}$: for the $i$th example, the predicted probability of the true label. (eg. Suppose a predicted probability for the $i$th example in 3-class classification is $[0.1, 0.4, 0.5]$ and the true label is $[0, 1, 0]$, then the $p_{it}$ is $0.4$)\n","* $\\alpha_{t}$: the $\\alpha$ correspond to the true label. (eg. With the above example, if your $\\alpha$ is $[1,2,3]$, then $\\alpha_{t} = 2$)\n","\n","**Note**: Since this equation computes the focal loss elementwisely, you can try to make it in the matrix form to speed up the computation!"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"99UXtihhuIZc"},"outputs":[],"source":["def compute_focal_loss(AL, Y, alpha, gamma):\n","\n","    # Compute loss from aL and y.\n","    ### START CODE HERE ### (10 line of code)\n","    n = Y.shape[0]\n","    loss = -1/n * np.sum(np.sum((alpha * Y) * np.power(1 - (AL * Y), gamma) * np.log((AL * Y) + 1e-5), axis=1))\n","    ### END CODE HERE ###\n","\n","    loss = np.squeeze(loss)\n","    assert(loss.shape == ())\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"mpQah0JDdMyl"},"source":["# Basic implementation (binary classification) (20%)\n","\n","Congratulations on implementing all the functions by yourself. You've done an incredible job! 👏\n","\n","Now, you have all the tools necessary to begin the classification. In this section, you'll build a binary classifier using the functions you previously wrote. Our goal is to use some patients' health information and predict whether their condition is worse than a given threshold after a period of time. The features have been preprocessed using min-max normalization and the data has been shuffled.\n","\n","**Exercise**: Implement a binary classifier and tune hyperparameter.\n","\n","**Instruction**:\n","* Use the functions you had previously written.\n","* You can try these two combinations for your last activation + loss function\n","    1. sigmoid + cross_entropy\n","    2. softmax + focal_loss\n","    \n","**Note**: More commonly, we set the output dimension to 1 and use the sigmoid function for binary classification. However, for simplicity in implementing focal loss, we treat binary classification as a multi-class classification. As a result, you first need to transform 'y' from a single label to a one-hot label. (eg.[[1], [0], [1], [0]] -> [[0, 1], [1, 0], [0, 1], [1, 0]]) Secondly, you must set your output dimension to 2 when using focal loss.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QpFQpiK5eF64"},"source":["## Helper function"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"woCqucFUYXe6"},"outputs":[],"source":["def predict(x, y_true, model):\n","    \"\"\"\n","    This function is used to predict the results of a  L-layer neural network.\n","\n","    Arguments:\n","    x -- data set of examples you would like to label\n","    model -- trained model\n","\n","    Returns:\n","    y_pred -- predictions for the given dataset X\n","    \"\"\"\n","\n","    n = x.shape[0]\n","\n","    # Forward propagation\n","    y_pred = model.forward(x)\n","\n","    # this transform the output and label of binary classification when using sigmoid + cross entropy for evaluation\n","    # eg. y_pred: [[0.8], [0.2], [0.1]] -> [[0.2, 0.8], [0.8, 0.2], [0.9, 0.1]]\n","    # eg. y_true: [[1], [0], [0]] -> [[0, 1], [1, 0], [1, 0]]\n","    if y_pred.shape[-1] == 1:\n","        y_pred = np.array([[1 - y[0], y[0]] for y in y_pred])\n","        if y_true is not None:\n","            y_true = np.array([[1,0] if y == 0 else [0,1] for y in y_true.reshape(-1)])\n","\n","    # make y_pred/y_true become one-hot prediction result\n","    # eg. y_true: [[1, 0, 0], [0, 0, 1], [0, 1, 0]] -> [0, 2, 1]\n","    # eg. y_pred: [[0.2, 0.41, 0.39], [0.1, 0.8, 0.1], [0.1, 0.1, 0.8]] -> [1, 1, 2]\n","    if y_true is not None:\n","        y_true = np.argmax(y_true, axis=1)\n","    y_pred = np.argmax(y_pred, axis=1)\n","\n","    if y_true is not None:\n","        # compute accuracy\n","        correct = 0\n","        for yt, yp in zip(y_true, y_pred):\n","            if yt == yp:\n","                correct += 1\n","        print(f\"Accuracy: {correct/n * 100:.2f}%\")\n","\n","        f1_scores = f1_score(y_true, y_pred, average=None)\n","        print(f'f1 score for each class: {f1_scores}')\n","        print(f'f1_macro score: {np.mean(np.array(f1_scores)):.2f}')\n","\n","    return y_pred"]},{"cell_type":"markdown","metadata":{"id":"vAvUwG1uSLg_"},"source":["## Read data & train_val split\n","\n","As you can see, the data distribution is imbalanced. Therefore, we can try using focal loss, which is an effective loss function designed to address imbalanced datasets. Let's delve into the the focal loss equation.\n","$$\n","\\text{Focal Loss} =\n","- \\sum_{i=1}^{n} \\alpha_t (1 - p_{it})^\\gamma \\log(p_{it})\n","$$\n","The parameter $\\alpha$ is an array of weighting factors for each class, which can be adjusted to balance the classes. The parameter $\\gamma$ acts as a modulating factor, reducing the loss contribution from well-classified examples. For instance, if $p_{it} = 0.9$, indicating a $90\\%$ confidence that the prediction for the $i$th example is correct, a higher $\\gamma$ value will result in a lower loss. You can adjust $\\alpha$ and $\\gamma$ based on the data distribution shown in the plot below.\n","\n","**Note**: When spliting data, you could try to plot and see if the data distribution is the same in training and validation to ensure the the correctness of your validation."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Cu8T1DKjb7Bn"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"pQ0xMNj7b-1q"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 200x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train: x=(353, 10), y=(353, 1)\n","Test: x=(89, 10)\n","x_train: (282, 10) | y_train: (282, 1)\n","x_val: (71, 10) | y_val: (71, 1)\n"]}],"source":["# load data\n","data = np.load('basic_data.npz')\n","X_train, Y_train = data[\"x_train\"], data[\"y_train\"]\n","X_test = data[\"x_test\"]\n","\n","# plot the data distribution\n","Y_train_1 = len(['_' for y in Y_train if y == 1])\n","Y_train_0 = len(['_' for y in Y_train if y == 0])\n","plt.figure(figsize=(2, 2))\n","plt.bar([0, 1], [Y_train_0, Y_train_1])\n","plt.title('Data distribution')\n","plt.xlabel('label')\n","plt.ylabel('counts')\n","plt.show()\n","\n","print('Train: x=%s, y=%s' % (X_train.shape, Y_train.shape))\n","print('Test: x=%s' % (X_test.shape, ))\n","\n","### START CODE HERE ###\n","# train_val split\n","n = X_train.shape[0]\n","x_train, y_train = X_train[:int(0.8*n)], Y_train[:int(0.8*n)]\n","x_val, y_val = X_train[int(0.8*n):], Y_train[int(0.8*n):]\n","### END CODE HERE ###\n","\n","print(\"x_train: \" + str(x_train.shape) + \" | y_train: \" + str(y_train.shape))\n","print(\"x_val: \" + str(x_val.shape) + \" | y_val: \" + str(y_val.shape))"]},{"cell_type":"markdown","metadata":{"id":"r01QzzHxeMbR"},"source":["## Training and Evaluation"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fI7JY5ESjhZ2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss after iteration 0: 0.633965\n"]},{"name":"stdout","output_type":"stream","text":["Loss after iteration 1000: 0.336708\n","Loss after iteration 2000: 0.331563\n","Loss after iteration 3000: 0.326895\n","Loss after iteration 4000: 0.317559\n","Loss after iteration 5000: 0.307287\n","Loss after iteration 6000: 0.298593\n","Loss after iteration 7000: 0.290400\n","Loss after iteration 8000: 0.282026\n","Loss after iteration 9000: 0.273362\n","Loss after iteration 10000: 0.263725\n","Loss after iteration 11000: 0.255093\n","Loss after iteration 12000: 0.247177\n","Loss after iteration 13000: 0.239530\n","Loss after iteration 14000: 0.232976\n","Loss after iteration 15000: 0.227393\n","Loss after iteration 16000: 0.222608\n","Loss after iteration 17000: 0.218254\n","Loss after iteration 18000: 0.214626\n","Loss after iteration 19000: 0.210806\n","Loss after iteration 20000: 0.207234\n","Loss after iteration 21000: 0.202960\n","Loss after iteration 22000: 0.199563\n","Loss after iteration 23000: 0.196840\n","Loss after iteration 24000: 0.193220\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 600x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# GRADED CODE: binary classification\n","### START CODE HERE ###\n","\n","loss_function = 'cross_entropy'\n","if loss_function == 'cross_entropy':\n","    layers_dims = [10, 9, 1]\n","    activation_fn = [\"relu\", \"sigmoid\"]\n","    gamma = None        # you can leave this as it is\n","    alpha = None        # you can leave this as it is\n","    y_train_processed = y_train\n","    y_val_processed = y_val\n","    assert y_train_processed.shape[-1] == 1, \"see the 'Note' in the Basic implementation section\"\n","    assert y_val_processed.shape[-1] == 1, \"see the 'Note' in the Basic implementation section\"\n","elif loss_function == 'focal_loss':\n","    layers_dims = [10, 5, 2]\n","    activation_fn = [\"relu\", \"softmax\"]\n","    gamma = 1\n","    alpha = np.array([0.5, 0.5])\n","    y_train_processed = np.array([[1 - y[0], y[0]] for y in y_train])\n","    y_val_processed = np.array([[1 - y[0], y[0]] for y in y_val])\n","    assert y_train_processed.shape[-1] == 2, \"see the 'Note' in the Basic implementation section\"\n","    assert y_val_processed.shape[-1] == 2, \"see the 'Note' in the Basic implementation section\"\n","\n","learning_rate = 0.06\n","num_iterations = 25000\n","print_loss = True\n","print_freq = 1000\n","classes = 2\n","losses = []                         # keep track of loss\n","model = Model(layers_dims, activation_fn, loss_function, alpha, gamma)\n","\n","# Loop (batch gradient descent)\n","for i in range(0, num_iterations):\n","    # forward\n","    AL = model.forward(x_train)\n","\n","    # compute loss\n","    if loss_function == 'cross_entropy':\n","        loss = compute_BCE_loss(AL=AL, Y=y_train_processed)\n","    elif loss_function == 'focal_loss':\n","        loss = compute_focal_loss(AL=AL, Y=y_train_processed, alpha=alpha, gamma=gamma)\n","\n","    # backward\n","    dA_prev = model.backward(AL=AL, Y=y_train_processed)\n","\n","    # update\n","    model.update(learning_rate)\n","\n","    losses.append(loss)\n","    if print_loss and i % print_freq == 0:\n","        print (\"Loss after iteration %i: %f\" %(i, loss))\n","\n","# plot the loss\n","plt.figure(figsize=(6, 3))\n","plt.plot(np.squeeze(losses))\n","plt.ylabel('loss')\n","plt.xlabel(f'iterations (per {print_freq})')\n","plt.title(\"Learning rate =\" + str(learning_rate))\n","plt.show()\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"U8q0a20XcPtk"},"outputs":[{"name":"stdout","output_type":"stream","text":["training------\n","Accuracy: 92.55%\n","f1 score for each class: [0.95035461 0.85106383]\n","f1_macro score: 0.90\n","validation------\n","Accuracy: 84.51%\n","f1 score for each class: [0.89320388 0.71794872]\n","f1_macro score: 0.81\n"]}],"source":["print('training------')\n","pred_train = predict(x_train, y_train_processed, model)\n","print('validation------')\n","pred_val = predict(x_val, y_val_processed, model)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"mERo3g41zsyX"},"outputs":[],"source":["pred_test = predict(X_test, None, model)\n","outputs[\"basic_pred_test\"] = pred_test"]},{"cell_type":"markdown","metadata":{"id":"oMCpPFMVdj36"},"source":["# Advanced implementation (multi class classification) (15%)\n","\n","In this section, you need to implement a multi-class classifier using the functions you had previously written. You will create a model that can classify ten handwritten digits. The MNIST handwritten digit classification problem is a standard dataset in computer vision and deep learning. We usually use convolutional deep-learning neural networks for image classification. However, using only dense layers appears to be enough to handle this simple dataset, and this is a good way to get started with image datasets.\n","\n","**Exercise**: Implement a multi-class classifier and tune hyperparameter.\n","\n","**Instruction**:\n","*   Use the functions you had previously written.\n","*   Preprocess the data to match the correct input format.\n","*   Use mini-batch gradient descent to train the model.\n","\n","**Hint**:\n","For data preprocessing, please be careful with the dimension of the inputs (X and y) and also note that the values of images are usually integers that fall between 0 and 255. You need to change the data type into float and scale the values between 0 and 1.\n","\n","In Batch Gradient Descent, we consider all the samples for every step of Gradient Descent. But what if our dataset is huge? You will get around 33000 training samples, then to take one step, the model will have to calculate the gradients of all the 33000 samples. This does not seem an efficient way. Hence, mini-batch gradient descent is recommended to be used in this part."]},{"cell_type":"markdown","metadata":{"id":"I_GQ3uO128OC"},"source":["## Read data & train_val split"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"1ew4u79ZuV5F"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"bVSfqnXqXGdC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: X=(31065, 28, 28), Y=(31065,)\n","Test: X=(7767, 28, 28)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 9 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["shape of X_train: (31065, 28, 28)\n","shape of Y_train: (31065, 10)\n","shape of X_test: (7767, 28, 28)\n","\n","shape of X_train: (31065, 784)\n","shape of Y_train: (31065, 10)\n","shape of X_test: (7767, 784)\n"]}],"source":["# load data\n","data = np.load('advanced_data.npz')\n","X_train = data[\"x_train\"]\n","Y_train = data[\"y_train\"]\n","X_test = data[\"x_test\"]\n","\n","# summarize loaded dataset\n","print(f'Train: X={X_train.shape}, Y={Y_train.shape}')\n","print(f'Test: X={X_test.shape}')\n","# plot first few images\n","for i in range(9):\n","\t# define subplot\n","\tplt.subplot(330 + 1 + i)\n","\t# plot raw pixel data\n","\tplt.imshow(X_train[i], cmap='gray', vmin=0, vmax=255)\n","# show the figure\n","plt.show()\n","\n","# GRADED CODE: multi-class classification (Data preprocessing) one-hot encoding for y\n","### START CODE HERE ###\n","Y_train = np.array([[1 if i == target else 0 for i in range(10)] for target in Y_train])\n","### END CODE HERE ###\n","\n","print(\"shape of X_train: \" + str(X_train.shape))\n","print(\"shape of Y_train: \" + str(Y_train.shape))\n","print(\"shape of X_test: \" + str(X_test.shape))\n","\n","# GRADED CODE: multi-class classification (Data preprocessing)\tnormalize x\n","### START CODE HERE ###\n","X_train = np.array([R.flatten() for R in X_train]) / 255\n","X_test = np.array([R.flatten() for R in X_test]) / 255\n","### END CODE HERE ###\n","\n","print(\"\\nshape of X_train: \" + str(X_train.shape))\n","print(\"shape of Y_train: \" + str(Y_train.shape))\n","print(\"shape of X_test: \" + str(X_test.shape))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ljAcf2tpQDR-"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of x_train: (24847, 784)\n","shape of y_train: (24847, 10)\n"]}],"source":["# You can split training and validation set here and visualize their distribution. (Optional)\n","# If not, just leave this as it is\n","### START CODE HERE ###\n","def train_test_split(X_train, Y_train):\n","    x_train = []\n","    y_train = []\n","    x_val = []\n","    y_val = []\n","    y_train_real = np.argmax(Y_train, axis=1)\n","    for i in range(10):\n","        index = np.where(y_train_real == i)\n","        x_i = X_train[index]\n","        x_train_split = x_i[:int(0.8*len(x_i))]\n","        x_val_split = x_i[int(0.8*len(x_i)):]\n","        for i in range(len(x_train_split)):\n","            x_train.append(x_train_split[i])\n","        for i in range(len(x_val_split)):            \n","            x_val.append(x_val_split[i])\n","        y_i = Y_train[index]\n","        y_train_split = y_i[:int(0.8*len(y_i))]\n","        y_val_split = y_i[int(0.8*len(y_i)):]\n","        for i in range(len(y_train_split)):\n","            y_train.append(y_train_split[i])        \n","        for i in range(len(y_val_split)):\n","            y_val.append(y_val_split[i])\n","    return np.asarray(x_train), np.asarray(y_train), np.asarray(x_val), np.asarray(y_val)\n","\n","x_train, y_train, x_val, y_val = train_test_split(X_train, Y_train)\n","\n","print(\"shape of x_train: \" + str(x_train.shape))\n","print(\"shape of y_train: \" + str(y_train.shape))\n","### END CODE HERE ###\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ngmUDGN13ADi"},"source":["## Training and Evaluation"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"HYD-qRs7doU0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss after iteration 0: 2.084428\n","Loss after iteration 100: 0.191143\n","Loss after iteration 200: 0.131578\n","Loss after iteration 300: 0.096347\n","Loss after iteration 400: 0.074335\n","Loss after iteration 500: 0.057365\n","Loss after iteration 600: 0.046183\n","Loss after iteration 700: 0.036651\n","Loss after iteration 800: 0.029436\n","Loss after iteration 900: 0.024086\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 400x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# GRADED CODE: multi-class classification\n","### START CODE HERE ###\n","def random_mini_batches(X, Y, mini_batch_size = 64):\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","\n","    Arguments:\n","    X -- input data, of shape (n, f^{0})\n","    Y -- true \"label\" vector, of shape (n, C)\n","    mini_batch_size -- size of the mini-batches, integer\n","\n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","\n","    m = X.shape[0]                  # number of training examples\n","    mini_batches = []\n","\n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = np.array([x_train[p, : ] for p in permutation])\n","    shuffled_Y = np.array([y_train[p, : ] for p in permutation])\n","\n","    # Step 2 - Partition (shuffled_X, shuffled_Y).\n","    # Cases with a complete mini batch size only i.e each of 64 examples.\n","    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        # (approx. 2 lines)\n","        mini_batch_X = shuffled_X[k * mini_batch_size: (k + 1) * mini_batch_size, : ]\n","        mini_batch_Y = shuffled_Y[k * mini_batch_size: (k + 1) * mini_batch_size, : ]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n","    if m % mini_batch_size != 0:\n","        #(approx. 2 lines)\n","        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size:, : ]\n","        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size:, : ]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","\n","    return mini_batches\n","\n","\n","layers_dims = [784, 256, 64, 10]\n","activation_fn = [\"relu\", \"relu\", \"softmax\"]\n","learning_rate = 0.003\n","num_iterations = 1000\n","batch_size = 200\n","classes = 10\n","losses = []                         # keep track of loss\n","print_loss = True\n","print_freq = 100\n","loss_function = 'cross_entropy'\n","gamma = None\n","alpha = None\n","model = Model(layers_dims, activation_fn, loss_function, alpha=alpha, gamma=gamma)\n","\n","# Loop (gradient descent)\n","for i in range(0, num_iterations):\n","    mini_batches = random_mini_batches(x_train, y_train, batch_size)\n","    loss = 0\n","    for batch in mini_batches:\n","        x_batch, y_batch = batch\n","\n","        # forward\n","        AL = model.forward(x_batch)\n","\n","        # compute loss\n","        if loss_function == 'cross_entropy':\n","            loss += compute_CCE_loss(AL=AL, Y=y_batch)\n","        elif loss_function == 'focal_loss':\n","            loss += compute_focal_loss(AL=AL, Y=y_batch, alpha=alpha, gamma=gamma)\n","\n","        # backward\n","        dA_prev = model.backward(AL=AL, Y=y_batch)\n","        # update\n","        model.update(learning_rate)\n","\n","    loss /= len(mini_batches)\n","    losses.append(loss)\n","    if print_loss and i % print_freq == 0:\n","        print (\"Loss after iteration %i: %f\" %(i, loss))\n","\n","\n","# plot the loss\n","plt.figure(figsize=(4, 2))\n","plt.plot(np.squeeze(losses))\n","plt.ylabel('loss')\n","plt.xlabel('iterations (per hundreds)')\n","plt.title(\"Learning rate =\" + str(learning_rate))\n","plt.show()\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"yI92fh4JXC1k"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 99.73%\n","f1 score for each class: [0.999094   0.99793725 0.99888018 0.9988992  0.99752617 0.99875653\n"," 0.99652174 0.99355301 0.98634812 0.9771167 ]\n","f1_macro score: 0.99\n"]}],"source":["pred_train = predict(x_train, y_train, model)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ehjcfSU2XD3-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 97.33%\n","f1 score for each class: [0.98331078 0.98783666 0.9749861  0.96677116 0.97791318 0.96620278\n"," 0.96969697 0.96709585 0.91079812 0.91402715]\n","f1_macro score: 0.96\n"]}],"source":["#You can check for your validation accuracy here. (Optional)\n","### START CODE HERE ###\n","pred_val = predict(x_val, y_val, model)\n","### END CODE HERE ###"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"YHFDuq2BQ2qI"},"outputs":[],"source":["pred_test = predict(X_test, None, model)\n","outputs[\"advanced_pred_test\"] = pred_test"]},{"cell_type":"markdown","metadata":{"id":"WXGnS3HQeNUc"},"source":["# Submit prediction"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"twMsmXbQeDL_"},"outputs":[],"source":["# sanity check\n","assert list(outputs.keys()) == [\n","    'basic_pred_test',\\\n","    'advanced_pred_test'],\\\n","\"You're missing something, please restart the kernel and run the code from begining to the end. If the same error occurs, maybe you deleted some outputs, check the template to find the missing parts!\""]},{"cell_type":"code","execution_count":22,"metadata":{"id":"bCJ0XTO_zE8A"},"outputs":[],"source":["np.save(\"output_bonus.npy\", outputs)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"2XTk5AdzyHkf"},"outputs":[{"name":"stdout","output_type":"stream","text":["basic_pred_test： <class 'numpy.ndarray'>\n","advanced_pred_test： <class 'numpy.ndarray'>\n"]}],"source":["# sanity check\n","submit = np.load(\"output_bonus.npy\", allow_pickle=True).item()\n","for key, value in submit.items():\n","  print(str(key) + \"： \" + str(type(value)))"]},{"cell_type":"markdown","metadata":{"id":"HXwjr9APIKt2"},"source":["**Notice**: We will not check the data type after \"compute_focal_loss\", (since you might be using focal loss in basic, then your basic_alpha wouldn't be None), so it is fine if you have different data type after \"compute_focal_loss\"."]},{"cell_type":"markdown","metadata":{"id":"trQqZni7jhP0"},"source":["Expected output: <br>\n","<small>\n","linear_forward： <class 'tuple'> <br>\n","linear_backward： <class 'tuple'> <br>\n","linear_update_parameters： <class 'dict'> <br>\n","sigmoid： <class 'tuple'> <br>\n","relu： <class 'tuple'> <br>\n","softmax： <class 'tuple'> <br>\n","sigmoid_backward： <class 'numpy.ndarray'> <br>\n","relu_backward： <class 'numpy.ndarray'> <br>\n","softmax_CCE_backward： <class 'numpy.ndarray'> <br>\n","softmax_Focal_backward： <class 'numpy.ndarray'> <br>\n","model_forward_sigmoid： <class 'tuple'> <br>\n","model_forward_relu： <class 'tuple'> <br>\n","model_forward_softmax： <class 'tuple'> <br>\n","model_backward_sigmoid： <class 'tuple'> <br>\n","model_backward_relu： <class 'tuple'> <br>\n","model_update_parameters： <class 'dict'> <br>\n","compute_BCE_loss： <class 'numpy.float64'> <br>\n","compute_CCE_loss： <class 'numpy.float64'> <br>\n","compute_focal_loss： <class 'numpy.float64'> <br>\n","basic_pred_test： <class 'numpy.ndarray'> <br>\n","basic_layers_dims： <class 'list'> <br>\n","basic_activation_fn： <class 'list'> <br>\n","basic_loss_function： <class 'str'> <br>\n","basic_alpha： <class 'NoneType'> <br>\n","basic_gamma： <class 'NoneType'> <br>\n","basic_model_parameters： <class 'list'> <br>\n","advanced_pred_test： <class 'numpy.ndarray'> <br>\n","advanced_layers_dims： <class 'list'> <br>\n","advanced_activation_fn： <class 'list'> <br>\n","advanced_loss_function： <class 'str'> <br>\n","advanced_alpha： <class 'numpy.ndarray'> <br>\n","advanced_gamma： <class 'float'> <br>\n","advanced_model_parameters： <class 'list'> <br>\n","</small>"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
